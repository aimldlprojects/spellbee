{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytesseract\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\eswar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "std = 3\n",
    "\n",
    "if std==3:\n",
    "    user = \"Madhu\"\n",
    "elif std==6:\n",
    "    user = \"bhavi\"\n",
    "else:\n",
    "    user = \"user\"\n",
    "\n",
    "sub = \"science\"\n",
    "lesson = 2\n",
    "file_name = str(std)+\"_\"+sub+\"_LS\"+str(lesson)\n",
    "\n",
    "images_folder_path = 'scanned_files' \n",
    "ext_txt_file_path = file_name+'_01_extracted_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder: ['20240302_090846.jpg', '20240302_090904.jpg', '20240302_090937.jpg', '20240302_090953.jpg', '20240302_091024.jpg', '20240302_091043.jpg', '20240302_091121.jpg', '20240302_091141.jpg', '20240302_091211.jpg', '20240302_091229.jpg', '20240302_091430.jpg']\n"
     ]
    }
   ],
   "source": [
    "# list all image files in the folder\n",
    "\n",
    "def list_files_in_folder(images_folder_path):\n",
    "    \"\"\"Lists all files in the given folder.\"\"\"\n",
    "    try:\n",
    "        # List all entries in the given folder\n",
    "        entries = os.listdir(images_folder_path)\n",
    "        files = [entry for entry in entries if os.path.isfile(os.path.join(images_folder_path, entry))]\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(\"The folder does not exist.\")\n",
    "        return []\n",
    "    except PermissionError:\n",
    "        print(\"Permission denied.\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "files = list_files_in_folder(images_folder_path)\n",
    "print(\"Files in folder:\", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the text from images and save to extracted_text.txt\n",
    "def extract_text_from_image(image_path):\n",
    "    # Open the image file\n",
    "    with Image.open(image_path) as img:\n",
    "        # Use pytesseract to extract text from the image\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text\n",
    "\n",
    "def extract_text_from_list_of_image(files):\n",
    "    pageno=1\n",
    "    # Open the file in append mode\n",
    "    with open(ext_txt_file_path, 'a') as data:\n",
    "        # Iterate through a range or any iterable\n",
    "        for file in files:\n",
    "            image_path = images_folder_path+'/'+file\n",
    "            page_no = f\"\\n\\nPage nummber: {pageno}\"+'\\n'\n",
    "            extracted_text = extract_text_from_image(image_path)\n",
    "            # Append text to the file\n",
    "            data.write(page_no+extracted_text)\n",
    "            pageno+=1\n",
    "\n",
    "extract_text_from_list_of_image(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rickets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbohydrates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Andhra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>pan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>aranerals)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>patch?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_words\n",
       "0          healthy\n",
       "1         rickets.\n",
       "2    Carbohydrates\n",
       "3             list\n",
       "4           revise\n",
       "..             ...\n",
       "968         Andhra\n",
       "969           pan.\n",
       "970     aranerals)\n",
       "971        Kitchen\n",
       "972         patch?\n",
       "\n",
       "[973 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique words from extracted text\n",
    "def get_unique_words(ext_txt_file_path):\n",
    "    unique_words = set()\n",
    "\n",
    "    # Open the file and read its contents\n",
    "    with open(ext_txt_file_path, 'r') as file:\n",
    "        # Read the text and split it into words\n",
    "        words = file.read().split()\n",
    "\n",
    "        # Add each word to the set of unique words\n",
    "        for word in words:\n",
    "            unique_words.add(word)\n",
    "\n",
    "    return unique_words\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "unique_words = get_unique_words(ext_txt_file_path)\n",
    "unique_words_list = list(unique_words)\n",
    "df = pd.DataFrame(unique_words_list)\n",
    "df.columns=['unique_words']\n",
    "df.to_csv(file_name+\"_02_unique_words.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\eswar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>andhra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_matched_words\n",
       "0              healthy\n",
       "1                 list\n",
       "2               revise\n",
       "3              correct\n",
       "4               powder\n",
       "..                 ...\n",
       "466                see\n",
       "467               made\n",
       "468                 we\n",
       "469             andhra\n",
       "470            kitchen\n",
       "\n",
       "[471 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the words that are not in dictionary\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Download the word list\n",
    "nltk.download('words')\n",
    "\n",
    "# List of English words provided by nltk\n",
    "english_vocab = set(w.lower() for w in words.words())\n",
    "\n",
    "def filter_english_words(word_list):\n",
    "    \"\"\"Filter the given list of words, keeping only English dictionary words.\"\"\"\n",
    "    # Convert all words in the list to lower case\n",
    "    word_list = [word.lower() for word in word_list]\n",
    "    # Filter the list to keep only words found in the English vocabulary\n",
    "    return [word for word in word_list if word in english_vocab]\n",
    "\n",
    "# Example usage:\n",
    "filtered_words = filter_english_words(unique_words_list)\n",
    "df_dict_matched_words = pd.DataFrame(filtered_words)\n",
    "df_dict_matched_words.columns=['dict_matched_words']\n",
    "df_dict_matched_words.to_csv(file_name+\"_03_dict_matched_words.csv\", index=False)\n",
    "df_dict_matched_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>andhra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_matched_filtered_words\n",
       "0                       healthy\n",
       "1                          list\n",
       "2                        revise\n",
       "3                       correct\n",
       "4                        powder\n",
       "..                          ...\n",
       "436                         see\n",
       "437                        made\n",
       "438                          we\n",
       "439                      andhra\n",
       "440                     kitchen\n",
       "\n",
       "[441 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted words that are manually notted\n",
    "df_unwanted_words = pd.read_csv(\"remove_unwanted_words.csv\")\n",
    "df_unwanted_words_list = df_unwanted_words[\"unwanted_words\"].to_list()\n",
    "\n",
    "filtered_words = pd.read_csv(file_name+\"_03_dict_matched_words.csv\")\n",
    "filtered_words = filtered_words[\"dict_matched_words\"]\n",
    "filtered_wanted_words = [word for word in filtered_words if word not in df_unwanted_words_list]\n",
    "df_dict_matched_words = pd.DataFrame(filtered_wanted_words)\n",
    "df_dict_matched_words.columns=['dict_matched_filtered_words']\n",
    "df_dict_matched_words.to_csv(file_name+\"_04_dict_matched_filtered_words.csv\", index=False)\n",
    "df_dict_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "def chunk_around_word(sentence, target_word, sentence_len=10):\n",
    "    cleaned_text = re.sub(r'\\n', ' ', sentence)\n",
    "    cleaned_text = re.sub(r'[^A-Za-z0-9 ]', '', cleaned_text)\n",
    "    sentence_lower = cleaned_text.lower()\n",
    "    target_word = target_word.lower()\n",
    "\n",
    "    sentence_len_left = int(sentence_len/2)\n",
    "    \n",
    "    words = sentence_lower.split()\n",
    "    target_index = words.index(target_word)  # Find the index of the target word\n",
    "\n",
    "    # Calculate start and end indices for slicing the words list\n",
    "    start_index = max(0, target_index - sentence_len_left)  # 5 words before\n",
    "    end_index = min(len(words), target_index + sentence_len_left)  # 4 words after, +1 because of slice behavior\n",
    "\n",
    "    # Join and return the chunk\n",
    "    chunk = ' '.join(words[start_index:end_index])\n",
    "    return chunk\n",
    "\n",
    "# find sentance with the given word\n",
    "def find_sentence_with_word(sentences, word):\n",
    "    word = word.lower()  # Convert the word to lowercase\n",
    "    sent = \"\"\n",
    "    cleaned_sentence = \"\"\n",
    "    for sentence in sentences:\n",
    "        cleaned_text = re.sub(r'\\n', ' ', sentence)\n",
    "        cleaned_text = re.sub(r'[^A-Za-z0-9 ]', '', cleaned_text)\n",
    "        if re.search(r'\\b{}\\b'.format(re.escape(word)), cleaned_text.lower()):\n",
    "            sent = sentence\n",
    "            cleaned_sentence = cleaned_text\n",
    "            break\n",
    "        else:\n",
    "            sent = \"\"\n",
    "            cleaned_sentence = \"\"\n",
    "\n",
    "    return sent, cleaned_sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eswar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# sentance spliter\n",
    "\n",
    "nltk.download('punkt')  # Download the required tokenizer data\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    # Use the nltk tokenizer to split the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "# Read the text file\n",
    "with open(ext_txt_file_path, \"r\", encoding=\"latin-1\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = split_into_sentences(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "      <th>sentence</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>chunked_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>Food component Food items\\n\\nProteins\\nCarbohy...</td>\n",
       "      <td>Food component Food items  Proteins Carbohydra...</td>\n",
       "      <td>to grow well and stay healthy we should have a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "      <td> list the harmful effects\\nof rotten food.</td>\n",
       "      <td>list the harmful effects of rotten food</td>\n",
       "      <td>list the harmful effects of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "      <td>aed Study Skills Seen\\n\\nComplete the flow cha...</td>\n",
       "      <td>aed Study Skills Seen  Complete the flow chart...</td>\n",
       "      <td>complete the flow chart to revise the differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "      <td>Tick (V) the correct option.</td>\n",
       "      <td>Tick V the correct option</td>\n",
       "      <td>tick v the correct option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "      <td>2\\nEvnariantial | aa ;\\n/ + Experiential Learn...</td>\n",
       "      <td>2 Evnariantial  aa    Experiential Learning  T...</td>\n",
       "      <td>a tablespoon each of coconut powder rice musta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>see</td>\n",
       "      <td>ame Se eee\\na, See\\n&amp; wemmoaniaians |\\n\\neo es...</td>\n",
       "      <td>ame Se eee a See  wemmoaniaians   eo es rns  IV</td>\n",
       "      <td>ame se eee a see wemmoaniaians eo es rns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>made</td>\n",
       "      <td>=\\n\\n\\n\\nPage nummber: 6\\nWater\\n\\nAlong with ...</td>\n",
       "      <td>Page nummber 6 Water  Along with food the ...</td>\n",
       "      <td>of the human body is made up of water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>we</td>\n",
       "      <td>\\n\\nPage nummber: 1\\n2 The Food We Eat\\n\\nLESS...</td>\n",
       "      <td>Page nummber 1 2 The Food We Eat  LESSON SCH...</td>\n",
       "      <td>nummber 1 2 the food we eat lesson schema pss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>andhra</td>\n",
       "      <td>Rajasthan \\nsaag, makke ki roti Dal-batti-chu...</td>\n",
       "      <td>Rajasthan  saag makke ki roti Dalbattichurma  ...</td>\n",
       "      <td>saag makke ki roti dalbattichurma andhra prade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>SESE It)Yourself\\n[= * Experiential Learning\\n...</td>\n",
       "      <td>SESE ItYourself   Experiential Learning  Kitch...</td>\n",
       "      <td>sese ityourself experiential learning kitchen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_matched_filtered_words  \\\n",
       "0                       healthy   \n",
       "1                          list   \n",
       "2                        revise   \n",
       "3                       correct   \n",
       "4                        powder   \n",
       "..                          ...   \n",
       "436                         see   \n",
       "437                        made   \n",
       "438                          we   \n",
       "439                      andhra   \n",
       "440                     kitchen   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    Food component Food items\\n\\nProteins\\nCarbohy...   \n",
       "1           list the harmful effects\\nof rotten food.   \n",
       "2    aed Study Skills Seen\\n\\nComplete the flow cha...   \n",
       "3                         Tick (V) the correct option.   \n",
       "4    2\\nEvnariantial | aa ;\\n/ + Experiential Learn...   \n",
       "..                                                 ...   \n",
       "436  ame Se eee\\na, See\\n& wemmoaniaians |\\n\\neo es...   \n",
       "437  =\\n\\n\\n\\nPage nummber: 6\\nWater\\n\\nAlong with ...   \n",
       "438  \\n\\nPage nummber: 1\\n2 The Food We Eat\\n\\nLESS...   \n",
       "439  Rajasthan \\nsaag, makke ki roti Dal-batti-chu...   \n",
       "440  SESE It)Yourself\\n[= * Experiential Learning\\n...   \n",
       "\n",
       "                                      cleaned_sentence  \\\n",
       "0    Food component Food items  Proteins Carbohydra...   \n",
       "1              list the harmful effects of rotten food   \n",
       "2    aed Study Skills Seen  Complete the flow chart...   \n",
       "3                            Tick V the correct option   \n",
       "4    2 Evnariantial  aa    Experiential Learning  T...   \n",
       "..                                                 ...   \n",
       "436    ame Se eee a See  wemmoaniaians   eo es rns  IV   \n",
       "437      Page nummber 6 Water  Along with food the ...   \n",
       "438    Page nummber 1 2 The Food We Eat  LESSON SCH...   \n",
       "439  Rajasthan  saag makke ki roti Dalbattichurma  ...   \n",
       "440  SESE ItYourself   Experiential Learning  Kitch...   \n",
       "\n",
       "                                      chunked_sentence  \n",
       "0       to grow well and stay healthy we should have a  \n",
       "1                          list the harmful effects of  \n",
       "2    complete the flow chart to revise the differen...  \n",
       "3                            tick v the correct option  \n",
       "4    a tablespoon each of coconut powder rice musta...  \n",
       "..                                                 ...  \n",
       "436           ame se eee a see wemmoaniaians eo es rns  \n",
       "437              of the human body is made up of water  \n",
       "438      nummber 1 2 the food we eat lesson schema pss  \n",
       "439  saag makke ki roti dalbattichurma andhra prade...  \n",
       "440  sese ityourself experiential learning kitchen ...  \n",
       "\n",
       "[441 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the sentence and chunk sentance columns\n",
    "df = pd.read_csv(file_name+\"_04_dict_matched_filtered_words.csv\")\n",
    "\n",
    "# Function to apply to each row\n",
    "def find_and_chunk(row, sentences):\n",
    "    word = row['dict_matched_filtered_words']\n",
    "    sentence, cleaned_sentence = find_sentence_with_word(sentences, word)\n",
    "    if sentence:\n",
    "        chunked_sentence = chunk_around_word(sentence, word)\n",
    "    else:\n",
    "        chunked_sentence = None\n",
    "    return pd.Series([sentence, cleaned_sentence, chunked_sentence])\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['sentence', 'cleaned_sentence', 'chunked_sentence']] = df.apply(find_and_chunk, args=(sentences,), axis=1)\n",
    "df.to_csv(file_name+\"_05_words_with_chunked_sentence.csv\", index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\eswar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eswar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Ensure you've downloaded the necessary NLTK resources\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load all sentences from the Brown Corpus\n",
    "brown_sentences = [' '.join(sent) for sent in brown.sents()]\n",
    "\n",
    "def find_example_sentence(word):\n",
    "    word = word.lower()\n",
    "    for sentence in brown_sentences:\n",
    "        if word in sentence.lower().split():\n",
    "            return sentence\n",
    "    return \"No example sentence found.\"\n",
    "\n",
    "def mask_word(word, sentence):\n",
    "    word = word.lower()\n",
    "    if re.search(r'\\b{}\\b'.format(re.escape(word)), sentence.lower()):\n",
    "        masked_sentence = sentence.lower().replace(word, '*' * len(word))\n",
    "    else:\n",
    "        masked_sentence = sentence\n",
    "    return masked_sentence.capitalize()  # Capitalize the first letter of the sentenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "      <th>sentence</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>chunked_sentence</th>\n",
       "      <th>masked_chunked_sentence</th>\n",
       "      <th>example_sentence</th>\n",
       "      <th>masked_example_sentence</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>Food component Food items\\n\\nProteins\\nCarbohy...</td>\n",
       "      <td>Food component Food items  Proteins Carbohydra...</td>\n",
       "      <td>to grow well and stay healthy we should have a</td>\n",
       "      <td>To grow well and stay ******* we should have a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "      <td> list the harmful effects\\nof rotten food.</td>\n",
       "      <td>list the harmful effects of rotten food</td>\n",
       "      <td>list the harmful effects of</td>\n",
       "      <td>**** the harmful effects of</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "      <td>aed Study Skills Seen\\n\\nComplete the flow cha...</td>\n",
       "      <td>aed Study Skills Seen  Complete the flow chart...</td>\n",
       "      <td>complete the flow chart to revise the differen...</td>\n",
       "      <td>Complete the flow chart to ****** the differen...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "      <td>Tick (V) the correct option.</td>\n",
       "      <td>Tick V the correct option</td>\n",
       "      <td>tick v the correct option</td>\n",
       "      <td>Tick v the ******* option</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "      <td>2\\nEvnariantial | aa ;\\n/ + Experiential Learn...</td>\n",
       "      <td>2 Evnariantial  aa    Experiential Learning  T...</td>\n",
       "      <td>a tablespoon each of coconut powder rice musta...</td>\n",
       "      <td>A tablespoon each of coconut ****** rice musta...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dict_matched_filtered_words  \\\n",
       "0                     healthy   \n",
       "1                        list   \n",
       "2                      revise   \n",
       "3                     correct   \n",
       "4                      powder   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Food component Food items\\n\\nProteins\\nCarbohy...   \n",
       "1         list the harmful effects\\nof rotten food.   \n",
       "2  aed Study Skills Seen\\n\\nComplete the flow cha...   \n",
       "3                       Tick (V) the correct option.   \n",
       "4  2\\nEvnariantial | aa ;\\n/ + Experiential Learn...   \n",
       "\n",
       "                                    cleaned_sentence  \\\n",
       "0  Food component Food items  Proteins Carbohydra...   \n",
       "1            list the harmful effects of rotten food   \n",
       "2  aed Study Skills Seen  Complete the flow chart...   \n",
       "3                          Tick V the correct option   \n",
       "4  2 Evnariantial  aa    Experiential Learning  T...   \n",
       "\n",
       "                                    chunked_sentence  \\\n",
       "0     to grow well and stay healthy we should have a   \n",
       "1                        list the harmful effects of   \n",
       "2  complete the flow chart to revise the differen...   \n",
       "3                          tick v the correct option   \n",
       "4  a tablespoon each of coconut powder rice musta...   \n",
       "\n",
       "                             masked_chunked_sentence example_sentence  \\\n",
       "0     To grow well and stay ******* we should have a                    \n",
       "1                        **** the harmful effects of                    \n",
       "2  Complete the flow chart to ****** the differen...                    \n",
       "3                          Tick v the ******* option                    \n",
       "4  A tablespoon each of coconut ****** rice musta...                    \n",
       "\n",
       "  masked_example_sentence openai_sentence masked_openai_sentence  \n",
       "0                                                                 \n",
       "1                                                                 \n",
       "2                                                                 \n",
       "3                                                                 \n",
       "4                                                                 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name+\"_05_words_with_chunked_sentence.csv\")\n",
    "\n",
    "# Add a column with the masked chunked sentence\n",
    "df['masked_chunked_sentence'] = df.apply(lambda row: mask_word(row['dict_matched_filtered_words'], row['chunked_sentence']), axis=1)\n",
    "\n",
    "#adding dummy columns openai_sentence,masked_openai_sentence\n",
    "df['example_sentence'] = \"\"\n",
    "df['masked_example_sentence'] = \"\"\n",
    "df['openai_sentence'] = \"\"\n",
    "df['masked_openai_sentence'] = \"\"\n",
    "df.to_csv(file_name+\"_06_words_with_chunked_eg_sentence.csv\", index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eswar\\AppData\\Local\\Temp\\ipykernel_6712\\2671655196.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[\"Hirsch's Scapin is healthy , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " \"Hirsch's Scapin is healthy , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " \"Hirsch's Scapin is healthy , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " ...\n",
      " \"Nevertheless , `` we feel that in the future Fulton County should receive some portion of these available funds '' , the jurors said .\"\n",
      " nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_merged.loc[df_merged['example_sentence_x'].isnull(), \"example_sentence_x\"]=df_merged.loc[df_merged['example_sentence_x'].isnull(), \"example_sentence_y\"]\n",
      "C:\\Users\\eswar\\AppData\\Local\\Temp\\ipykernel_6712\\2671655196.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[\"Hirsch's scapin is ******* , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " \"Hirsch's scapin is ******* , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " \"Hirsch's scapin is ******* , cheerful , energetic , revelling in his physical agility and his obvious superiority to the young gentlemen whom he serves .\"\n",
      " ...\n",
      " \"Nevertheless , `` ** feel that in the future fulton county should receive some portion of these available funds '' , the jurors said .\"\n",
      " nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_merged.loc[df_merged['masked_example_sentence_x'].isnull(), \"masked_example_sentence_x\"]=df_merged.loc[df_merged['masked_example_sentence_x'].isnull(), \"masked_example_sentence_y\"]\n",
      "C:\\Users\\eswar\\AppData\\Local\\Temp\\ipykernel_6712\\2671655196.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[\"It's important to stay healthy.\" \"It's important to stay healthy.\"\n",
      " \"It's important to stay healthy.\" ... 'We play at recess.' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_merged.loc[df_merged['openai_sentence_x'].isnull(), \"openai_sentence_x\"]=df_merged.loc[df_merged['openai_sentence_x'].isnull(), \"openai_sentence_y\"]\n",
      "C:\\Users\\eswar\\AppData\\Local\\Temp\\ipykernel_6712\\2671655196.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[\"It's important to stay *******.\" \"It's important to stay *******.\"\n",
      " \"It's important to stay *******.\" ... '** play at recess.' nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_merged.loc[df_merged['masked_openai_sentence_x'].isnull(), \"masked_openai_sentence_x\"]=df_merged.loc[df_merged['masked_openai_sentence_x'].isnull(), \"masked_openai_sentence_y\"]\n"
     ]
    }
   ],
   "source": [
    "# update openai sentences from master wordlist\n",
    "df = pd.read_csv(file_name+\"_06_words_with_chunked_eg_sentence.csv\")\n",
    "# Read the word_list_all CSV file into df1\n",
    "df1 = pd.read_csv('word_list_all.csv')\n",
    "\n",
    "# Merge df with df1\n",
    "df_merged = pd.merge(df, df1, how='left', left_on='dict_matched_filtered_words', right_on='word')\n",
    "df_merged.loc[df_merged['example_sentence_x'].isnull(), \"example_sentence_x\"]=df_merged.loc[df_merged['example_sentence_x'].isnull(), \"example_sentence_y\"]\n",
    "df_merged.loc[df_merged['masked_example_sentence_x'].isnull(), \"masked_example_sentence_x\"]=df_merged.loc[df_merged['masked_example_sentence_x'].isnull(), \"masked_example_sentence_y\"]\n",
    "df_merged.loc[df_merged['openai_sentence_x'].isnull(), \"openai_sentence_x\"]=df_merged.loc[df_merged['openai_sentence_x'].isnull(), \"openai_sentence_y\"]\n",
    "df_merged.loc[df_merged['masked_openai_sentence_x'].isnull(), \"masked_openai_sentence_x\"]=df_merged.loc[df_merged['masked_openai_sentence_x'].isnull(), \"masked_openai_sentence_y\"]\n",
    "\n",
    "df_merged.drop(['user','word','chunked_sentence_y','masked_chunked_sentence_y', 'example_sentence_y', 'masked_example_sentence_y', 'openai_sentence_y', 'masked_openai_sentence_y'], axis=1, inplace=True)\n",
    "df_merged.rename(columns={'chunked_sentence_x':'chunked_sentence', 'masked_chunked_sentence_x':'masked_chunked_sentence', 'example_sentence_x':'example_sentence', 'masked_example_sentence_x':'masked_example_sentence', 'openai_sentence_x':'openai_sentence', 'masked_openai_sentence_x':'masked_openai_sentence'}, inplace=True)\n",
    "df_merged['word_type']=file_name\n",
    "df_merged=df_merged[['dict_matched_filtered_words', 'word_type', 'sentence', 'cleaned_sentence',\n",
    "       'chunked_sentence', 'masked_chunked_sentence',\n",
    "       'example_sentence', 'masked_example_sentence',\n",
    "       'openai_sentence', 'masked_openai_sentence']]\n",
    "df_merged.drop_duplicates(inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "      <th>word_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>chunked_sentence</th>\n",
       "      <th>masked_chunked_sentence</th>\n",
       "      <th>example_sentence</th>\n",
       "      <th>masked_example_sentence</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>Food component Food items\\n\\nProteins\\nCarbohy...</td>\n",
       "      <td>Food component Food items  Proteins Carbohydra...</td>\n",
       "      <td>to grow well and stay healthy we should have a</td>\n",
       "      <td>To grow well and stay ******* we should have a</td>\n",
       "      <td>Hirsch's Scapin is healthy , cheerful , energe...</td>\n",
       "      <td>Hirsch's scapin is ******* , cheerful , energe...</td>\n",
       "      <td>It's important to stay healthy.</td>\n",
       "      <td>It's important to stay *******.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td> list the harmful effects\\nof rotten food.</td>\n",
       "      <td>list the harmful effects of rotten food</td>\n",
       "      <td>list the harmful effects of</td>\n",
       "      <td>**** the harmful effects of</td>\n",
       "      <td>The Central Falls City Council expressed conce...</td>\n",
       "      <td>The central falls city council expressed conce...</td>\n",
       "      <td>Make a list of your toys.</td>\n",
       "      <td>Make a **** of your toys.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>aed Study Skills Seen\\n\\nComplete the flow cha...</td>\n",
       "      <td>aed Study Skills Seen  Complete the flow chart...</td>\n",
       "      <td>complete the flow chart to revise the differen...</td>\n",
       "      <td>Complete the flow chart to ****** the differen...</td>\n",
       "      <td>Tom was not willing to revise the play accordi...</td>\n",
       "      <td>Tom was not willing to ****** the play accordi...</td>\n",
       "      <td>Let's revise our essays.</td>\n",
       "      <td>let's ****** our essays.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>Tick (V) the correct option.</td>\n",
       "      <td>Tick V the correct option</td>\n",
       "      <td>tick v the correct option</td>\n",
       "      <td>Tick v the ******* option</td>\n",
       "      <td>He assured Mr. Martinelli and the council that...</td>\n",
       "      <td>He assured mr. martinelli and the council that...</td>\n",
       "      <td>Circle the correct answer.</td>\n",
       "      <td>Circle the ******* answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>2\\nEvnariantial | aa ;\\n/ + Experiential Learn...</td>\n",
       "      <td>2 Evnariantial  aa    Experiential Learning  T...</td>\n",
       "      <td>a tablespoon each of coconut powder rice musta...</td>\n",
       "      <td>A tablespoon each of coconut ****** rice musta...</td>\n",
       "      <td>'' Despite Company threats , duly carried thro...</td>\n",
       "      <td>'' despite company threats , duly carried thro...</td>\n",
       "      <td>Add a teaspoon of cocoa powder.</td>\n",
       "      <td>Add a teaspoon of cocoa ******.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dict_matched_filtered_words      word_type  \\\n",
       "0                     healthy  3_science_LS2   \n",
       "1                        list  3_science_LS2   \n",
       "2                      revise  3_science_LS2   \n",
       "3                     correct  3_science_LS2   \n",
       "4                      powder  3_science_LS2   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Food component Food items\\n\\nProteins\\nCarbohy...   \n",
       "1         list the harmful effects\\nof rotten food.   \n",
       "2  aed Study Skills Seen\\n\\nComplete the flow cha...   \n",
       "3                       Tick (V) the correct option.   \n",
       "4  2\\nEvnariantial | aa ;\\n/ + Experiential Learn...   \n",
       "\n",
       "                                    cleaned_sentence  \\\n",
       "0  Food component Food items  Proteins Carbohydra...   \n",
       "1            list the harmful effects of rotten food   \n",
       "2  aed Study Skills Seen  Complete the flow chart...   \n",
       "3                          Tick V the correct option   \n",
       "4  2 Evnariantial  aa    Experiential Learning  T...   \n",
       "\n",
       "                                    chunked_sentence  \\\n",
       "0     to grow well and stay healthy we should have a   \n",
       "1                        list the harmful effects of   \n",
       "2  complete the flow chart to revise the differen...   \n",
       "3                          tick v the correct option   \n",
       "4  a tablespoon each of coconut powder rice musta...   \n",
       "\n",
       "                             masked_chunked_sentence  \\\n",
       "0     To grow well and stay ******* we should have a   \n",
       "1                        **** the harmful effects of   \n",
       "2  Complete the flow chart to ****** the differen...   \n",
       "3                          Tick v the ******* option   \n",
       "4  A tablespoon each of coconut ****** rice musta...   \n",
       "\n",
       "                                    example_sentence  \\\n",
       "0  Hirsch's Scapin is healthy , cheerful , energe...   \n",
       "1  The Central Falls City Council expressed conce...   \n",
       "2  Tom was not willing to revise the play accordi...   \n",
       "3  He assured Mr. Martinelli and the council that...   \n",
       "4  '' Despite Company threats , duly carried thro...   \n",
       "\n",
       "                             masked_example_sentence  \\\n",
       "0  Hirsch's scapin is ******* , cheerful , energe...   \n",
       "1  The central falls city council expressed conce...   \n",
       "2  Tom was not willing to ****** the play accordi...   \n",
       "3  He assured mr. martinelli and the council that...   \n",
       "4  '' despite company threats , duly carried thro...   \n",
       "\n",
       "                   openai_sentence           masked_openai_sentence  \n",
       "0  It's important to stay healthy.  It's important to stay *******.  \n",
       "1        Make a list of your toys.        Make a **** of your toys.  \n",
       "2         Let's revise our essays.         let's ****** our essays.  \n",
       "3       Circle the correct answer.       Circle the ******* answer.  \n",
       "4  Add a teaspoon of cocoa powder.  Add a teaspoon of cocoa ******.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column with an example sentence from the Brown Corpus\n",
    "df_merged.loc[df_merged['example_sentence'].isnull(), 'example_sentence']= df_merged.loc[df_merged['example_sentence'].isnull(), 'dict_matched_filtered_words'].apply(find_example_sentence)\n",
    "\n",
    "# Add a column with the masked example sentence\n",
    "df_merged['masked_example_sentence'] = df_merged.apply(lambda row: mask_word(row['dict_matched_filtered_words'], row['example_sentence']), axis=1)\n",
    "df_merged.to_csv(file_name+\"_10_merged_df_with_existing_openai_sentence.csv\", index=False)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "      <th>openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prefer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coastal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vomiting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sesame</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>culinary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edible</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>distinct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cumin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>papaya</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chill</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>union</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>terry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pleasant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>consuming</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>germinate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bitter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>territory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aide</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>slimy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rotten</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>moist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>scatter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>athlete</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tablespoon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>safflower</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ab</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>carton</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>nina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>evaluate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nancy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>stale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>josh</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>necessity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>freshly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>incredible</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>patch</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lots</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>oily</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>eta</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>elderly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>andhra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dict_matched_filtered_words openai_sentence\n",
       "0                         code             NaN\n",
       "1                       prefer             NaN\n",
       "2                        spoil             NaN\n",
       "3                           fa             NaN\n",
       "4                      coastal             NaN\n",
       "5                           wy             NaN\n",
       "6                     vomiting             NaN\n",
       "7                       unique             NaN\n",
       "8                      kitchen             NaN\n",
       "9                       sesame             NaN\n",
       "10                    culinary             NaN\n",
       "11                      edible             NaN\n",
       "12                    distinct             NaN\n",
       "13                       cumin             NaN\n",
       "14                      papaya             NaN\n",
       "15                       chill             NaN\n",
       "16                       union             NaN\n",
       "17                        scan             NaN\n",
       "18                       terry             NaN\n",
       "19                         mae             NaN\n",
       "20                    pleasant             NaN\n",
       "21                         bon             NaN\n",
       "22                   consuming             NaN\n",
       "23                   germinate             NaN\n",
       "24                      bitter             NaN\n",
       "25                        sour             NaN\n",
       "26                   territory             NaN\n",
       "27                        aide             NaN\n",
       "28                       slimy             NaN\n",
       "29                      rotten             NaN\n",
       "30                       moist             NaN\n",
       "31                     scatter             NaN\n",
       "32                     athlete             NaN\n",
       "33                  tablespoon             NaN\n",
       "34                     injured             NaN\n",
       "35                   safflower             NaN\n",
       "36                          ab             NaN\n",
       "37                      carton             NaN\n",
       "38                        nina             NaN\n",
       "39                    evaluate             NaN\n",
       "40                       nancy             NaN\n",
       "41                       stale             NaN\n",
       "42                        josh             NaN\n",
       "43                   necessity             NaN\n",
       "44                     freshly             NaN\n",
       "45                  incredible             NaN\n",
       "46                       patch             NaN\n",
       "47                        lots             NaN\n",
       "48                   newspaper             NaN\n",
       "49                        mary             NaN\n",
       "50                          sa             NaN\n",
       "51                        oily             NaN\n",
       "52                         eta             NaN\n",
       "53                        pack             NaN\n",
       "54                     elderly             NaN\n",
       "55                      andhra             NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing null values in openai sentences\n",
    "df = pd.read_csv(file_name+\"_06_words_with_chunked_eg_sentence.csv\")\n",
    "df = df_merged.loc[df_merged['openai_sentence'].isnull(),['dict_matched_filtered_words','openai_sentence']]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.to_csv(file_name+\"_07_blank_openai_sentence.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_matched_filtered_words</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aide</td>\n",
       "      <td>The teacher's aide helps us.</td>\n",
       "      <td>the teacher's **** helps us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andhra</td>\n",
       "      <td>Andhra Pradesh is in India.</td>\n",
       "      <td>****** pradesh is in india.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>athlete</td>\n",
       "      <td>She is a talented athlete.</td>\n",
       "      <td>she is a talented *******.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bitter</td>\n",
       "      <td>The medicine tasted bitter.</td>\n",
       "      <td>the medicine tasted ******.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bone</td>\n",
       "      <td>The dog chewed on a bone.</td>\n",
       "      <td>the dog chewed on a ****.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dict_matched_filtered_words                openai_sentence  \\\n",
       "0                        aide   The teacher's aide helps us.   \n",
       "1                      andhra    Andhra Pradesh is in India.   \n",
       "2                     athlete     She is a talented athlete.   \n",
       "3                      bitter    The medicine tasted bitter.   \n",
       "4                        bone      The dog chewed on a bone.   \n",
       "\n",
       "          masked_openai_sentence  \n",
       "0   the teacher's **** helps us.  \n",
       "1    ****** pradesh is in india.  \n",
       "2     she is a talented *******.  \n",
       "3    the medicine tasted ******.  \n",
       "4      the dog chewed on a ****.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding masked openai sentence to new words. \n",
    "# Manually enter the openai sentences using chatgpt and then use this funtion to fill masked sentance.\n",
    "# Add a column with the masked example sentence\n",
    "try:\n",
    "    df = pd.read_csv(file_name+\"_08_openai_sentence.csv\")\n",
    "    df['masked_openai_sentence'] = df.apply(lambda row: mask_word(row['dict_matched_filtered_words'], row['openai_sentence']), axis=1)\n",
    "    df.to_csv(file_name+\"_09_masked_openai_sentence.csv\", index=False)\n",
    "except:\n",
    "    print(\"Manually enter the openai sentences using chatgpt and then use this funtion to fill masked sentance.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>chunked_sentence</th>\n",
       "      <th>masked_chunked_sentence</th>\n",
       "      <th>example_sentence</th>\n",
       "      <th>masked_example_sentence</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>to grow well and stay healthy we should have a</td>\n",
       "      <td>To grow well and stay ******* we should have a</td>\n",
       "      <td>Hirsch's Scapin is healthy , cheerful , energe...</td>\n",
       "      <td>Hirsch's scapin is ******* , cheerful , energe...</td>\n",
       "      <td>It's important to stay healthy.</td>\n",
       "      <td>It's important to stay *******.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>list the harmful effects of</td>\n",
       "      <td>**** the harmful effects of</td>\n",
       "      <td>The Central Falls City Council expressed conce...</td>\n",
       "      <td>The central falls city council expressed conce...</td>\n",
       "      <td>Make a list of your toys.</td>\n",
       "      <td>Make a **** of your toys.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revise</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>complete the flow chart to revise the differen...</td>\n",
       "      <td>Complete the flow chart to ****** the differen...</td>\n",
       "      <td>Tom was not willing to revise the play accordi...</td>\n",
       "      <td>Tom was not willing to ****** the play accordi...</td>\n",
       "      <td>Let's revise our essays.</td>\n",
       "      <td>let's ****** our essays.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correct</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>tick v the correct option</td>\n",
       "      <td>Tick v the ******* option</td>\n",
       "      <td>He assured Mr. Martinelli and the council that...</td>\n",
       "      <td>He assured mr. martinelli and the council that...</td>\n",
       "      <td>Circle the correct answer.</td>\n",
       "      <td>Circle the ******* answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powder</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>a tablespoon each of coconut powder rice musta...</td>\n",
       "      <td>A tablespoon each of coconut ****** rice musta...</td>\n",
       "      <td>'' Despite Company threats , duly carried thro...</td>\n",
       "      <td>'' despite company threats , duly carried thro...</td>\n",
       "      <td>Add a teaspoon of cocoa powder.</td>\n",
       "      <td>Add a teaspoon of cocoa ******.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>human</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>the human body needs activities</td>\n",
       "      <td>The ***** body needs activities</td>\n",
       "      <td>It made him human .</td>\n",
       "      <td>It made him ***** .</td>\n",
       "      <td>Every human has a heart.</td>\n",
       "      <td>Every ***** has a heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>elderly</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>age elderly people may like to</td>\n",
       "      <td>Age ******* people may like to</td>\n",
       "      <td>Of the two cherished achievements the elderly ...</td>\n",
       "      <td>Of the two cherished achievements the ******* ...</td>\n",
       "      <td>The elderly man needs assistance.</td>\n",
       "      <td>the ******* man needs assistance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>see</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>ame se eee a see wemmoaniaians eo es rns</td>\n",
       "      <td>Ame se eee a *** wemmoaniaians eo es rns</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>I see a bird in the tree.</td>\n",
       "      <td>I *** a bird in the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>made</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>of the human body is made up of water</td>\n",
       "      <td>Of the human body is **** up of water</td>\n",
       "      <td>Before adjournment Monday afternoon , the Sena...</td>\n",
       "      <td>Before adjournment monday afternoon , the sena...</td>\n",
       "      <td>I made a paper airplane.</td>\n",
       "      <td>I **** a paper airplane.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>andhra</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>saag makke ki roti dalbattichurma andhra prade...</td>\n",
       "      <td>Saag makke ki roti dalbattichurma ****** prade...</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>Andhra Pradesh is in India.</td>\n",
       "      <td>****** pradesh is in india.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      word_type  \\\n",
       "0    healthy  3_science_LS2   \n",
       "1       list  3_science_LS2   \n",
       "2     revise  3_science_LS2   \n",
       "3    correct  3_science_LS2   \n",
       "4     powder  3_science_LS2   \n",
       "..       ...            ...   \n",
       "387    human  3_science_LS2   \n",
       "388  elderly  3_science_LS2   \n",
       "389      see  3_science_LS2   \n",
       "390     made  3_science_LS2   \n",
       "391   andhra  3_science_LS2   \n",
       "\n",
       "                                      chunked_sentence  \\\n",
       "0       to grow well and stay healthy we should have a   \n",
       "1                          list the harmful effects of   \n",
       "2    complete the flow chart to revise the differen...   \n",
       "3                            tick v the correct option   \n",
       "4    a tablespoon each of coconut powder rice musta...   \n",
       "..                                                 ...   \n",
       "387                    the human body needs activities   \n",
       "388                     age elderly people may like to   \n",
       "389           ame se eee a see wemmoaniaians eo es rns   \n",
       "390              of the human body is made up of water   \n",
       "391  saag makke ki roti dalbattichurma andhra prade...   \n",
       "\n",
       "                               masked_chunked_sentence  \\\n",
       "0       To grow well and stay ******* we should have a   \n",
       "1                          **** the harmful effects of   \n",
       "2    Complete the flow chart to ****** the differen...   \n",
       "3                            Tick v the ******* option   \n",
       "4    A tablespoon each of coconut ****** rice musta...   \n",
       "..                                                 ...   \n",
       "387                    The ***** body needs activities   \n",
       "388                     Age ******* people may like to   \n",
       "389           Ame se eee a *** wemmoaniaians eo es rns   \n",
       "390              Of the human body is **** up of water   \n",
       "391  Saag makke ki roti dalbattichurma ****** prade...   \n",
       "\n",
       "                                      example_sentence  \\\n",
       "0    Hirsch's Scapin is healthy , cheerful , energe...   \n",
       "1    The Central Falls City Council expressed conce...   \n",
       "2    Tom was not willing to revise the play accordi...   \n",
       "3    He assured Mr. Martinelli and the council that...   \n",
       "4    '' Despite Company threats , duly carried thro...   \n",
       "..                                                 ...   \n",
       "387                                It made him human .   \n",
       "388  Of the two cherished achievements the elderly ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment Monday afternoon , the Sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                               masked_example_sentence  \\\n",
       "0    Hirsch's scapin is ******* , cheerful , energe...   \n",
       "1    The central falls city council expressed conce...   \n",
       "2    Tom was not willing to ****** the play accordi...   \n",
       "3    He assured mr. martinelli and the council that...   \n",
       "4    '' despite company threats , duly carried thro...   \n",
       "..                                                 ...   \n",
       "387                                It made him ***** .   \n",
       "388  Of the two cherished achievements the ******* ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment monday afternoon , the sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                        openai_sentence              masked_openai_sentence  \n",
       "0       It's important to stay healthy.     It's important to stay *******.  \n",
       "1             Make a list of your toys.           Make a **** of your toys.  \n",
       "2              Let's revise our essays.            let's ****** our essays.  \n",
       "3            Circle the correct answer.          Circle the ******* answer.  \n",
       "4       Add a teaspoon of cocoa powder.     Add a teaspoon of cocoa ******.  \n",
       "..                                  ...                                 ...  \n",
       "387            Every human has a heart.            Every ***** has a heart.  \n",
       "388   The elderly man needs assistance.   the ******* man needs assistance.  \n",
       "389           I see a bird in the tree.           I *** a bird in the tree.  \n",
       "390            I made a paper airplane.            I **** a paper airplane.  \n",
       "391         Andhra Pradesh is in India.         ****** pradesh is in india.  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the new openai sentances with existing sheet\n",
    "df =  pd.read_csv(file_name+\"_10_merged_df_with_existing_openai_sentence.csv\")\n",
    "df1 = pd.read_csv(file_name+\"_09_masked_openai_sentence.csv\")\n",
    "df1.columns = ['dict_matched_filtered_words', 'openai_sentence_new', 'masked_openai_sentence_new']\n",
    "\n",
    "df_merged = pd.merge(df, df1, how='left', on='dict_matched_filtered_words')\n",
    "df_merged.loc[df_merged['openai_sentence'].isnull(), \"openai_sentence\"]=df_merged.loc[df_merged['openai_sentence'].isnull(), \"openai_sentence_new\"]\n",
    "df_merged.loc[df_merged['masked_openai_sentence'].isnull(), \"masked_openai_sentence\"]=df_merged.loc[df_merged['masked_openai_sentence'].isnull(), \"masked_openai_sentence_new\"]\n",
    "df_merged.drop(columns=['sentence', 'cleaned_sentence', 'openai_sentence_new','masked_openai_sentence_new'], inplace=True)\n",
    "df_merged.rename(columns={'dict_matched_filtered_words':'word'}, inplace=True)\n",
    "\n",
    "df_merged.to_csv(file_name+\"_11_word_list.csv\", index=False)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>chunked_sentence</th>\n",
       "      <th>masked_chunked_sentence</th>\n",
       "      <th>example_sentence</th>\n",
       "      <th>masked_example_sentence</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>about</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Highway Department source told The Constit...</td>\n",
       "      <td>The highway department source told the constit...</td>\n",
       "      <td>This book is about animals.</td>\n",
       "      <td>This book is ***** animals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "      <td>after</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He will be succeeded by Ivan Allen Jr. , who b...</td>\n",
       "      <td>He will be succeeded by ivan allen jr. , who b...</td>\n",
       "      <td>Lunch is after class.</td>\n",
       "      <td>Lunch is ***** class.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user</td>\n",
       "      <td>all</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`` This is one of the major items in the Fulto...</td>\n",
       "      <td>`` this is one of the major items in the fulto...</td>\n",
       "      <td>All the cookies are gone.</td>\n",
       "      <td>*** the cookies are gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user</td>\n",
       "      <td>am</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`` But I am not in favor of a sales or state i...</td>\n",
       "      <td>`` but i ** not in favor of a sales or state i...</td>\n",
       "      <td>I am happy today.</td>\n",
       "      <td>I ** happy today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user</td>\n",
       "      <td>an</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>The fulton county gr**d jury said friday ** in...</td>\n",
       "      <td>I saw an elephant.</td>\n",
       "      <td>I saw ** eleph**t.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>human</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>the human body needs activities</td>\n",
       "      <td>The ***** body needs activities</td>\n",
       "      <td>It made him human .</td>\n",
       "      <td>It made him ***** .</td>\n",
       "      <td>Every human has a heart.</td>\n",
       "      <td>Every ***** has a heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>elderly</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>age elderly people may like to</td>\n",
       "      <td>Age ******* people may like to</td>\n",
       "      <td>Of the two cherished achievements the elderly ...</td>\n",
       "      <td>Of the two cherished achievements the ******* ...</td>\n",
       "      <td>The elderly man needs assistance.</td>\n",
       "      <td>the ******* man needs assistance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>see</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>ame se eee a see wemmoaniaians eo es rns</td>\n",
       "      <td>Ame se eee a *** wemmoaniaians eo es rns</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>I see a bird in the tree.</td>\n",
       "      <td>I *** a bird in the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>made</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>of the human body is made up of water</td>\n",
       "      <td>Of the human body is **** up of water</td>\n",
       "      <td>Before adjournment Monday afternoon , the Sena...</td>\n",
       "      <td>Before adjournment monday afternoon , the sena...</td>\n",
       "      <td>I made a paper airplane.</td>\n",
       "      <td>I **** a paper airplane.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>andhra</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>saag makke ki roti dalbattichurma andhra prade...</td>\n",
       "      <td>Saag makke ki roti dalbattichurma ****** prade...</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>Andhra Pradesh is in India.</td>\n",
       "      <td>****** pradesh is in india.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6067 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user     word      word_type  \\\n",
       "0     user    about    Sight Words   \n",
       "1     user    after    Sight Words   \n",
       "2     user      all    Sight Words   \n",
       "3     user       am    Sight Words   \n",
       "4     user       an    Sight Words   \n",
       "..     ...      ...            ...   \n",
       "387  Madhu    human  3_science_LS2   \n",
       "388  Madhu  elderly  3_science_LS2   \n",
       "389  Madhu      see  3_science_LS2   \n",
       "390  Madhu     made  3_science_LS2   \n",
       "391  Madhu   andhra  3_science_LS2   \n",
       "\n",
       "                                      chunked_sentence  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "387                    the human body needs activities   \n",
       "388                     age elderly people may like to   \n",
       "389           ame se eee a see wemmoaniaians eo es rns   \n",
       "390              of the human body is made up of water   \n",
       "391  saag makke ki roti dalbattichurma andhra prade...   \n",
       "\n",
       "                               masked_chunked_sentence  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "387                    The ***** body needs activities   \n",
       "388                     Age ******* people may like to   \n",
       "389           Ame se eee a *** wemmoaniaians eo es rns   \n",
       "390              Of the human body is **** up of water   \n",
       "391  Saag makke ki roti dalbattichurma ****** prade...   \n",
       "\n",
       "                                      example_sentence  \\\n",
       "0    The Highway Department source told The Constit...   \n",
       "1    He will be succeeded by Ivan Allen Jr. , who b...   \n",
       "2    `` This is one of the major items in the Fulto...   \n",
       "3    `` But I am not in favor of a sales or state i...   \n",
       "4    The Fulton County Grand Jury said Friday an in...   \n",
       "..                                                 ...   \n",
       "387                                It made him human .   \n",
       "388  Of the two cherished achievements the elderly ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment Monday afternoon , the Sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                               masked_example_sentence  \\\n",
       "0    The highway department source told the constit...   \n",
       "1    He will be succeeded by ivan allen jr. , who b...   \n",
       "2    `` this is one of the major items in the fulto...   \n",
       "3    `` but i ** not in favor of a sales or state i...   \n",
       "4    The fulton county gr**d jury said friday ** in...   \n",
       "..                                                 ...   \n",
       "387                                It made him ***** .   \n",
       "388  Of the two cherished achievements the ******* ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment monday afternoon , the sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                        openai_sentence              masked_openai_sentence  \n",
       "0           This book is about animals.         This book is ***** animals.  \n",
       "1                 Lunch is after class.               Lunch is ***** class.  \n",
       "2             All the cookies are gone.           *** the cookies are gone.  \n",
       "3                     I am happy today.                   I ** happy today.  \n",
       "4                    I saw an elephant.                  I saw ** eleph**t.  \n",
       "..                                  ...                                 ...  \n",
       "387            Every human has a heart.            Every ***** has a heart.  \n",
       "388   The elderly man needs assistance.   the ******* man needs assistance.  \n",
       "389           I see a bird in the tree.           I *** a bird in the tree.  \n",
       "390            I made a paper airplane.            I **** a paper airplane.  \n",
       "391         Andhra Pradesh is in India.         ****** pradesh is in india.  \n",
       "\n",
       "[6067 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updating the word list and word list all\n",
    "df1 = pd.read_csv(\"word_list.csv\")\n",
    "df2 =  pd.read_csv(file_name+\"_11_word_list.csv\")\n",
    "df2['user'] = user\n",
    "columns=['user', 'word', 'word_type', 'chunked_sentence', 'masked_chunked_sentence', 'example_sentence', 'masked_example_sentence', 'openai_sentence', 'masked_openai_sentence']\n",
    "df2=df2[columns]\n",
    "df_appended = pd.concat([df1, df2])\n",
    "df_appended = df_appended.drop_duplicates()\n",
    "df_appended.to_csv(\"word_list.csv\", index=False)\n",
    "df_appended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>chunked_sentence</th>\n",
       "      <th>masked_chunked_sentence</th>\n",
       "      <th>example_sentence</th>\n",
       "      <th>masked_example_sentence</th>\n",
       "      <th>openai_sentence</th>\n",
       "      <th>masked_openai_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>about</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Highway Department source told The Constit...</td>\n",
       "      <td>The highway department source told the constit...</td>\n",
       "      <td>This book is about animals.</td>\n",
       "      <td>This book is ***** animals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "      <td>after</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He will be succeeded by Ivan Allen Jr. , who b...</td>\n",
       "      <td>He will be succeeded by ivan allen jr. , who b...</td>\n",
       "      <td>Lunch is after class.</td>\n",
       "      <td>Lunch is ***** class.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user</td>\n",
       "      <td>all</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`` This is one of the major items in the Fulto...</td>\n",
       "      <td>`` this is one of the major items in the fulto...</td>\n",
       "      <td>All the cookies are gone.</td>\n",
       "      <td>*** the cookies are gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user</td>\n",
       "      <td>am</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`` But I am not in favor of a sales or state i...</td>\n",
       "      <td>`` but i ** not in favor of a sales or state i...</td>\n",
       "      <td>I am happy today.</td>\n",
       "      <td>I ** happy today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user</td>\n",
       "      <td>an</td>\n",
       "      <td>Sight Words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>The fulton county gr**d jury said friday ** in...</td>\n",
       "      <td>I saw an elephant.</td>\n",
       "      <td>I saw ** eleph**t.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>human</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>the human body needs activities</td>\n",
       "      <td>The ***** body needs activities</td>\n",
       "      <td>It made him human .</td>\n",
       "      <td>It made him ***** .</td>\n",
       "      <td>Every human has a heart.</td>\n",
       "      <td>Every ***** has a heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>elderly</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>age elderly people may like to</td>\n",
       "      <td>Age ******* people may like to</td>\n",
       "      <td>Of the two cherished achievements the elderly ...</td>\n",
       "      <td>Of the two cherished achievements the ******* ...</td>\n",
       "      <td>The elderly man needs assistance.</td>\n",
       "      <td>the ******* man needs assistance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>see</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>ame se eee a see wemmoaniaians eo es rns</td>\n",
       "      <td>Ame se eee a *** wemmoaniaians eo es rns</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>Barber , who is in his 13th year as a legislat...</td>\n",
       "      <td>I see a bird in the tree.</td>\n",
       "      <td>I *** a bird in the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>made</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>of the human body is made up of water</td>\n",
       "      <td>Of the human body is **** up of water</td>\n",
       "      <td>Before adjournment Monday afternoon , the Sena...</td>\n",
       "      <td>Before adjournment monday afternoon , the sena...</td>\n",
       "      <td>I made a paper airplane.</td>\n",
       "      <td>I **** a paper airplane.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Madhu</td>\n",
       "      <td>andhra</td>\n",
       "      <td>3_science_LS2</td>\n",
       "      <td>saag makke ki roti dalbattichurma andhra prade...</td>\n",
       "      <td>Saag makke ki roti dalbattichurma ****** prade...</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>No example sentence found.</td>\n",
       "      <td>Andhra Pradesh is in India.</td>\n",
       "      <td>****** pradesh is in india.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6067 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user     word      word_type  \\\n",
       "0     user    about    Sight Words   \n",
       "1     user    after    Sight Words   \n",
       "2     user      all    Sight Words   \n",
       "3     user       am    Sight Words   \n",
       "4     user       an    Sight Words   \n",
       "..     ...      ...            ...   \n",
       "387  Madhu    human  3_science_LS2   \n",
       "388  Madhu  elderly  3_science_LS2   \n",
       "389  Madhu      see  3_science_LS2   \n",
       "390  Madhu     made  3_science_LS2   \n",
       "391  Madhu   andhra  3_science_LS2   \n",
       "\n",
       "                                      chunked_sentence  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "387                    the human body needs activities   \n",
       "388                     age elderly people may like to   \n",
       "389           ame se eee a see wemmoaniaians eo es rns   \n",
       "390              of the human body is made up of water   \n",
       "391  saag makke ki roti dalbattichurma andhra prade...   \n",
       "\n",
       "                               masked_chunked_sentence  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "387                    The ***** body needs activities   \n",
       "388                     Age ******* people may like to   \n",
       "389           Ame se eee a *** wemmoaniaians eo es rns   \n",
       "390              Of the human body is **** up of water   \n",
       "391  Saag makke ki roti dalbattichurma ****** prade...   \n",
       "\n",
       "                                      example_sentence  \\\n",
       "0    The Highway Department source told The Constit...   \n",
       "1    He will be succeeded by Ivan Allen Jr. , who b...   \n",
       "2    `` This is one of the major items in the Fulto...   \n",
       "3    `` But I am not in favor of a sales or state i...   \n",
       "4    The Fulton County Grand Jury said Friday an in...   \n",
       "..                                                 ...   \n",
       "387                                It made him human .   \n",
       "388  Of the two cherished achievements the elderly ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment Monday afternoon , the Sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                               masked_example_sentence  \\\n",
       "0    The highway department source told the constit...   \n",
       "1    He will be succeeded by ivan allen jr. , who b...   \n",
       "2    `` this is one of the major items in the fulto...   \n",
       "3    `` but i ** not in favor of a sales or state i...   \n",
       "4    The fulton county gr**d jury said friday ** in...   \n",
       "..                                                 ...   \n",
       "387                                It made him ***** .   \n",
       "388  Of the two cherished achievements the ******* ...   \n",
       "389  Barber , who is in his 13th year as a legislat...   \n",
       "390  Before adjournment monday afternoon , the sena...   \n",
       "391                         No example sentence found.   \n",
       "\n",
       "                        openai_sentence              masked_openai_sentence  \n",
       "0           This book is about animals.         This book is ***** animals.  \n",
       "1                 Lunch is after class.               Lunch is ***** class.  \n",
       "2             All the cookies are gone.           *** the cookies are gone.  \n",
       "3                     I am happy today.                   I ** happy today.  \n",
       "4                    I saw an elephant.                  I saw ** eleph**t.  \n",
       "..                                  ...                                 ...  \n",
       "387            Every human has a heart.            Every ***** has a heart.  \n",
       "388   The elderly man needs assistance.   the ******* man needs assistance.  \n",
       "389           I see a bird in the tree.           I *** a bird in the tree.  \n",
       "390            I made a paper airplane.            I **** a paper airplane.  \n",
       "391         Andhra Pradesh is in India.         ****** pradesh is in india.  \n",
       "\n",
       "[6067 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updating the word list and word list all\n",
    "df1 = pd.read_csv(\"word_list_all.csv\")\n",
    "df2 =  pd.read_csv(file_name+\"_11_word_list.csv\")\n",
    "df2['user'] = user\n",
    "columns=['user', 'word', 'word_type', 'chunked_sentence', 'masked_chunked_sentence', 'example_sentence', 'masked_example_sentence', 'openai_sentence', 'masked_openai_sentence']\n",
    "df2=df2[columns]\n",
    "df_appended = pd.concat([df1, df2])\n",
    "df_appended = df_appended.drop_duplicates()\n",
    "df_appended.to_csv(\"word_list_all.csv\", index=False)\n",
    "df_appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
